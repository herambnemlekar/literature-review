## Other methods for symbolic representation and planning
1. [Inducing probabilistic context-free grammars for the sequencing of movement primitives](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8460190)
	- Assumptions: 1) We assume each segment of the observed sequences to be a sample from an underlying library of movement primitives. 2) Any produced sequence has to result in a continuous trajectory inside the state space. By restricting the operators to only produce valid grammars.
	- Definitions: 1) A probabilistic context-free grammar (PCFG) is a 4-tuple G = (A,V,R,S), where A is a set of terminals, V is a set of non terminals, S is a set of starting symbols and R = {(A,R,ρ)| A∈V} is a set of production rules. 2) Learning formal grammars from sequences of terminalsis referred to as grammar induction.
	- PCFG for movement primitives: 1) Θ is set of primitives and D is set of labelled demonstrations. 2) define the set of terminals as the set of primitives A = Θ i.e. primitives are immutable, implying that the search space consists of grammars that only differ in S, V or R. 3) Each grammar is a node in the grammar space, while the directed edges between nodes are defined by operators. Operators manipulate the rule set R of a grammar G to create a new grammar G′. 4) Posterior optimization- G* = argmax p(G|D) = argmax p(D|G) p(G). This is the total probability of the set of demonstrations D given a grammar G. 5) p(D|G) = ∏ p(d|G). 6) p(d|G)= (1/|parse (d,G)|) ∑_{τ∈parse(d,G)} ∏_{(A,r,ρ)∈τ} ρ. This is the average probability over each tree that produces the demonstartion d from grammar G. 7) Grammar prior is joint distribution over grammar probabilities ρ_G = {ρ_A | A∈V} and grammar structure G_R = {ρ_A | A∈V}. 
	- Traversing grammar space: 1) We define a domain Ω_op for each operator op ∈ O, that op can act on. 2) After creating new grammar G', parameters have to be recomputed using Inside-Outside algorithm. 3) Every sequence produced by G has to guarantee a smooth, continuous trajectory within the statespace of the MPs. We restrict the grammar space G to only contain grammars that fulfill this continuity requirement. The restriction is achieved by limiting the domain Ω_op of each operator, such that if grammar G fulfills the continuity requirement any grammar G′resulting from an application of op on G also fulfills the requirement.
	- Summary: Demonstrations are segmented to get primitives. Primitives are immutable. We start from a grammar prior. Each grammar is defined by terminals (A), non-terminals (V), rules (R) and starting symbols (S). Each rule has productions, each of which is a sequence. We apply operators to rules of the previous grammar to get new grammar. The operators are applied such that the new grammar can fit to all demonstrations. The operator changes the rules and non-terminals such that the new rules have new productions (sequences). The rules define how a tree will expand from the start symbols.

1. [State representation learning (SRL) for control: An overview](https://arxiv.org/pdf/1802.04181.pdf)
	- SRL is a case of feature learning where the featuresto learn are low dimensional, evolve through time, and are influenced by actions or interactions. SRL learns a mapping φ of the history of observation to the current state s_t=φ(o_{1:t}). 
	- Difference: reduces the state space from S∈R^d to some S∈R^d' where d'<< d. While symbolic representation reduces state space to a set S∈Ω where |Ω|∈R.

1. [Learning and reasoning with action-related places for robust mobile manipulation](https://www.jair.org/index.php/jair/article/download/10744/25663)
	- Abstract: 1) Represent robot locations as a collection of positions each associated with a probability that a manipulation action will succeed from it. 2) ARPlace generated through xperience-based learning. 3) ARPlace updated based on new task information. 4) Least-commitment approach. Transformational planner optimizes symbolic plans.
	- ARPlace: The probability of successful manipulation given the current estimate of object position (and robot positions).
	- Planning: 1) RPL
	- Similarity to symbol intersections: 1) Because grasping both cups at once from a single position is much more efficient than approaching two locations, the robot merges the two ARPlaces for each cup into one ARPlace representing the probability of successfully grasping both cups from a single position.
	- Difference to symbol intersections: 1) Requires 'flaw detection' to identify better options. Pre-defined flaws. Additional information like collisions, supporting planes and other concepts of the world is needed. 2) For RPL, expressions and objects need to be annotated
	- Similarity to parameterized symbols: 1) Learn SVM for a task parameterization. Use Point Distribution Models to generalize over SVMs for several task parameterizations. Choose 20 landmarks (points) on the classification boundary corresponding to each of the 16 object positions. Arrange the x and y of each point in a 40x16 matrix where each column is 20 x and 20 y of the landmarks for an object position. Represent each boundary as mean + (k x variance). Use regression to interpolate over parameters like k.
	- Limitation: 1) Is it assumed that moving close to an initial ARPlace estimate will result in information gain leading to a better ARPlace estimate? No explicit modelling of information seeking behaviour. 2) To collect data the robot repeatedly executes a specific action sequence. 3) Features w.r.t. table? Rather should be w.r.t. robot. As everything would be consistent w.r.t. robot. 4) What if the grasps are failed during data collection due to some other factor and not due to robot position? 5) The boundaries of SVMs may not be regression-able. We don't know that an interpolation would actually work in real world.

1. [CRAM—A Cognitive Robot Abstract Machine for everyday manipulation in human environments](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5650146)